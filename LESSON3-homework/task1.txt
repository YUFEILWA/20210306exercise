javascript在储存数值时遵守IEEE.754规范，
二进制里面带二进制里面带分母的分数只有2的倍数才能被有限的表示。
因为0.1的分母是10，0.2的分母是5都不是2的倍数，所以这些数字不能被有限小数表示。
为了以IEEE 754浮点数保存这些小数，不得不把这些尾数进行四舍五入，半进度的10位，单精度的23位，双精度的52位。
根据不同的精度位数，浮点数会把0.1和0.2转化比其数学表示大或者小的数。正因为如此0.1+0.2总是不等于0.3

如：
 // 0.1 转化为二进制
0.0 0011 0011 0011 0011...(0011无限循环）

// 0.2 转化为二进制
0.0011 0011 0011 0011 0011...(0011无限循环）
由于尾数只有52位，所以对于0.1和0.2转换后的二进制如下：

e = -4; m =1.1001100110011001100110011001100110011001100110011010 (52位)
e = -3; m =1.1001100110011001100110011001100110011001100110011010 (52位)

0.1+0.2 结果表示成二进制：

1.00110011001100110011001100110011001100110011001100111（52位）

最终表示为：
0 01111111101 0011001100110011001100110011001100110011001100110100

计算过程中，计算机做三次四舍五入，保存每个数字各一次，保存最终结果一次。
而单纯的保存0.3的时候，只做了一次四舍五入。
正是四舍五入导致了0.1+0.2的结果跟0.3的表示不一致。

